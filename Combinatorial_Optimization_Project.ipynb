{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinatorial Optimization \n",
    "\n",
    "1. Edit Distance\n",
    "2. Huffman Codes\n",
    "\n",
    "##### General Set-Up\n",
    "- Write text of at most 6 pages containing a discussion of the problem, propsed algo. and proof of correctness.\n",
    "- Include references!!\n",
    "- Write complete computer code, each line commented indicating meaning and flow of the algorithm\n",
    "- Check correctness\n",
    "- Report output of the algorithm on the data sets provided\n",
    "\n",
    "Deliverable:\n",
    "Single PDF file with discusison of problem and proposed algorithm. Proof of correctness, complexity as a function of input size, brief discussion of the paradigm (greedy, dynamic, divide and conquer). Code, References, Output.\n",
    "\n",
    "\n",
    "#### 1. Edit Distance\n",
    "\n",
    "1. Discussion of the problem\n",
    "Given two strings of text, measure the distance between them using the following operations:\n",
    "\n",
    "- D: Deletion\n",
    "- I: Insertion\n",
    "- S: Substitution\n",
    "\n",
    "Edit distance $d(X,Y)$ is the minimum number of operations needed to perform on X to produce Y.\n",
    "\n",
    "3. Proof of correctness\n",
    "4. Complexity\n",
    "5. Implementation of the code\n",
    "6. Output\n",
    "\n",
    "\n",
    "Use dynmaic programming -> Solve smaller subproblems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistance('ACTACTAGATTACTTACGGATCAGGTACTTTAGAGGCTTGCAACCA','TACTAGCTTACTTACCCATCAGGTTTTAGAGATGGCAACCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huffman Codes\n",
    "\n",
    "##### Discussion of the problem\n",
    "\n",
    "- Find the minimal encoding for a given text. \n",
    "- Enconding means writing the text using bits (zeros and ones)\n",
    "- Naive approach would be to use a fixed number of bits for each symbol in the alphabet, example: 32 symbols to encode, use 5 bits per symbol $2^5 = 32$ symbols. (Kleinberg, Tardos)\n",
    "- Question is: Do we really need to use 5 bits for every symbol? Some symbols are being used more often than others. From a data storage persepective it would be wasteful to encode all symbols with the same number of bits. In the example above, we would need $32*5$ bits to encode the alphabet, the space, comma, period, question mark and exclamation point.\n",
    "- We could also use a smaller number of bits to encode the symbols that are more frequent! For example, \"a\" is a lot more frequent than \"x\" in the english alphabet. \n",
    "- The question is now, how to find an optimal encoding, so that the encoding is minimal (minimum \"size\").\n",
    "- On the other hand, the encoding should ensure that a coded text can be decoded unambigously\n",
    "\n",
    "Solution: Use Variable-Length encoding schemes\n",
    "\n",
    "In comes the prefix code: Say we want to transport a message using only zeros and ones. The message looks like a big string of zeros and ones. Lets say we've encoded \"a\" as a \"1\", b as \"0\" and c as \"01\". A string \"abc\" would then theoretically look like this: \"1001\". However, an algorithm which tries to decode this string would traverse over the zeros and ones and then return a letter once it finds a match. In this case, in the first step the algorithm would find the \"1\" and return \"a\". In the second step it would find the \"0\" and return a \"b\"; so far so good. However, in the third step, the algorithm would again stop at the \"0\" and return another \"b\". The decoded string would then be \"abba\" and not \"abc\". The issue here is, that the encoding for \"b\" is a prefix of the enconding for \"c\".  We therefore have to find an encoding that maps letters to bit strings so that no bit string is the prefix of another. It is no problem however, if a bit string is a sub string of another string, as long as it's not a prefix! (Kleinberg, Tardos). \n",
    "\n",
    "The question is now: How do we get an optimal set of prefixes, so that \n",
    "\n",
    "1: We can en- and decode a given set of symbols unambigously\n",
    "2: The encoding takes up minimal space.\n",
    "\n",
    "How is minimal space defined?\n",
    "\n",
    "Each symbol $s \\in T$ (Text T) occurs with a  given frequency $f_s$. The encoding of $s$ is $c(s)$ where $c(s)$ represents a binary string. The average number of bits required to encode a given text is then:\n",
    "\n",
    "$$\\sum_{s \\in T}^{} f_s \\mid c(s) \\mid $$ \n",
    "\n",
    "where $\\mid c(s) \\mid $ denotes the length of the encoding $c(s)$, number of bits.\n",
    "The question is now: How do we find the optimal encoding?\n",
    "\n",
    "#### The Huffman Code - Algorithm\n",
    "\n",
    "What to discuss here:\n",
    "- Just the algorithm\n",
    "- Proof of correctness (-> it is a prefix code, it is minimal, etc) in the second part.\n",
    "\n",
    "Use a greedy method to construct an optimal prefix code! (Kleinberg, Tardos).\n",
    "\n",
    "- Use binary trees\n",
    "- Number of leaves is equal to the size of the alphabet (unique symbols in text S)\n",
    "- each leaf is labeled with a distinct letter S\n",
    "- This binary tree naturally describes a prefix code\n",
    "- For each letter \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a helper function for getting the alphabet of the current text. \n",
    "# The alphabet defines the frequency of every letter in the current text.\n",
    "def get_alphabet(text):\n",
    "    \n",
    "    # Initialize empty array in which letters and letter counts can be stored as key : value pairs\n",
    "    alphabet = {}\n",
    "    \n",
    "    # For every unique letter in the text (including signs and spaces), add a letter : count(letter) pair to the dict.\n",
    "    for letter in set(text):\n",
    "        alphabet.update({letter: text.count(letter) / len(text)})\n",
    "    \n",
    "    # Return the filled dictionary\n",
    "    return alphabet\n",
    "\n",
    "# Defining a helper function for assigning the actual prefix code to a given set of nodes in a tree.\n",
    "# The helper function receives a set of nodes in the form of a dictionary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function for getting the optimal prefix of a given text\n",
    "def get_prefix(text):\n",
    "    \n",
    "    # Get the alphabet of the input text. The frequencies of the symbols will be needed to \n",
    "    # form the prefixes.\n",
    "    \n",
    "    alphabet = get_alphabet(text)\n",
    "    \n",
    "    # Set up empty dictionary. Each entry in the dictionary will represent a node in the\n",
    "    # Optimal prefix tree.\n",
    "    nodes =  {}\n",
    "    \n",
    "    # Initialize the tree, assigning all symbols of the alphabet to a leaf in the tree.\n",
    "    for symbol in alphabet.keys():\n",
    "        nodes[symbol] = []\n",
    "        \n",
    "    # Now comes the step of generating \"meta-symbols\"\n",
    "    # As long as the alphabet contains more than one symbol, take the two symbols \"x\" and \"y\" with\n",
    "    # the lowest frequency f_x , f_y and merge them into a 'meta-symbol' \"xy\" with the frequency f_x + f_y\n",
    "    # Remove the letters x and y from the alphabet and replace them with their \"meta\"-symbol'. Further, add\n",
    "    # the meta symbols to the set of nodes. These meta symbols are actual nodes in the final tree. \n",
    "    # The while loop finishes when there's only one 'meta-symbol' left which has frequency one. This \n",
    "    # will be the root of the tree.\n",
    "    \n",
    "    # Repeat until alphabet has been shrunk to length 1\n",
    "    while len(alphabet) > 1:\n",
    "        \n",
    "        # Sort the current instance of the alphabet in reverse order so that the symbols / meta -\n",
    "        # symbols with the lowest frequency can be extracted.\n",
    "        # This returns a list with the first entry of the list being the symbol with lowest frequency\n",
    "        sorted_alphabet = sorted(alphabet.items(),key=lambda x:x[1]) \n",
    "        \n",
    "        # Return the two letters / meta-letters x and y with the lowest frequency of the current \n",
    "        # instance of the alphabet. This will be merged into a new meta letter and added to the set of nodes\n",
    "        \n",
    "        # Symbol with lowest frequency (just the symbol)\n",
    "        x = sorted_alphabet[0][0]\n",
    "        \n",
    "        # Symbol with lowest frequency (just the symbol)\n",
    "        y = sorted_alphabet[1][0]\n",
    "        \n",
    "        # Delete them from the alphabet, making a new combined letter 'xy' with the combined frequency\n",
    "        # dict.pop(foo) removes the 'foo' entry from the dict, returning its value\n",
    "        # Adding alph.pop(x) + alph.pop(y) together removes x and y from the dict, while \n",
    "        # summing their frequencies The sum of the frequencies is assigned to a \n",
    "        # new 'meta'-letter with key \"xy\" and frequency f_x + f_y\n",
    "        alphabet[x+y] = alphabet.pop(x) + alphabet.pop(y) \n",
    "    \n",
    "        # Add the new meta letter \"xy\" to the tree. The meta letter has key \"xy\" and a list \n",
    "        # of the symbols x and y as a value.\n",
    "        nodes[x+y] = [x, y]\n",
    "        \n",
    "    # Once the nodes have been built, the codes can be assigned by traversing the tree. Starting\n",
    "    # from the root node which is the last meta-letter that has been added in the while loop.\n",
    "    # Set up root node\n",
    "    root = x + y\n",
    "    \n",
    "    # Set up an empty dictonary which will store the symbols and prefix codes \n",
    "    # This will be handed down to the helper function, which will fill it up\n",
    "    code = {}\n",
    "\n",
    "        \n",
    "        \n",
    "    return code\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [], 'b': [], 'c': [], 'cb': ['c', 'b'], 'acb': ['a', 'cb']}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prefix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [], 'b': [], 'c': [], 'cb': ['c', 'b'], 'acb': ['a', 'cb']}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Call the helper function get_nodes\n",
    "tree = assign_code(nodes, root, code)   # assignment of the code for the given binary tree      \n",
    "    return code, tree\n",
    "\n",
    "\n",
    "# Start at the root of the tree, return the children of the root. \n",
    "# This can either be a list of two, then we are in a node, or a list of one, then we've reached a leaf\n",
    "children = nodes[root]\n",
    "\n",
    "# If we are in a leaf (list is of length one), split the tree, hand down the prefix string\n",
    "if len(children) == 2:\n",
    "    tree['0'] = children[0]\n",
    "    tree['1'] = children[1]\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-126-99b9c1ba350b>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-126-99b9c1ba350b>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Get the children of the current node (saved as a list of the meta node)\n",
    "childs = nodes[root]\n",
    "\n",
    "# Set up empty tree\n",
    "tree = {}\n",
    "\n",
    "# If the length of the childs is 2, recursively call assign_code\n",
    "# if len(childs) == 2:\n",
    "#        tree['0'] = assign_code(nodes, childs[0], result, prefix+'0')\n",
    "#        tree['1'] = assign_code(nodes, childs[1], result, prefix+'1')     \n",
    "#        return tree\n",
    "# If the length of the childs is not two, assign no prefix\n",
    "code[label] = prefix\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Huffman_code(_vals):    \n",
    "    vals = _vals.copy()\n",
    "    nodes = {}\n",
    "    for n in vals.keys(): # leafs initialization\n",
    "        nodes[n] = []\n",
    "\n",
    "    while len(vals) > 1: # binary tree creation\n",
    "        s_vals = sorted(vals.items(), key=lambda x:x[1]) \n",
    "        a1 = s_vals[0][0]\n",
    "        a2 = s_vals[1][0]\n",
    "        vals[a1+a2] = vals.pop(a1) + vals.pop(a2)\n",
    "        nodes[a1+a2] = [a1, a2]        \n",
    "    code = {}\n",
    "    root = a1+a2\n",
    "    tree = {}\n",
    "    tree = assign_code(nodes, root, code)   # assignment of the code for the given binary tree      \n",
    "    return code, tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': '00', 'e': '010', 'd': '011', 'b': '10', 'a': '11'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = {'a' : 0.32,\n",
    "            'b' : 0.25,\n",
    "            'c' : 0.2,\n",
    "            'd' : 0.18,\n",
    "            'e' : 0.05}\n",
    "\n",
    "code, tree = Huffman_code(alphabet)\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': '00', 'e': '010', 'd': '011', 'b': '10', 'a': '11'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = {'a' : 0.32,\n",
    "            'b' : 0.25,\n",
    "            'c' : 0.2,\n",
    "            'd' : 0.18,\n",
    "            'e' : 0.05}\n",
    "\n",
    "code, tree = Huffman_code(alphabet)\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"O all you host of heaven! O earth! What else? And shall I couple hell? Oh, fie! Hold,\n",
    "hold, my heart, And you, my sinews, grow not instant old, But bear me stiffly up. Remember\n",
    "thee! Ay, thou poor ghost, whiles memory holds a seat In this distracted globe. Remember thee!\n",
    "Yea, from the table of my memory I’ll wipe away all trivial fond records, All saws of books, all\n",
    "forms, all pressures past That youth and observation copied there, And thy commandment all\n",
    "alone shall live Within the book and volume of my brain, Unmixed with baser matter. Yes, by\n",
    "heaven! O most pernicious woman! O villain, villain, smiling, damned villain! My tables! Meet it\n",
    "is I set it down That one may smile, and smile, and be a villain. At least I’m sure it may be so in\n",
    "Denmark. So, uncle, there you are. Now to my word.\"\"\"\n",
    "\n",
    "text2 = \"\"\"Habe nun, ach! Philosophie, Juristerei und Medizin, Und leider auch Theologie\n",
    "Durchaus studiert, mit heissem Bem¨uhn. Da steh ich nun, ich armer Tor! Und bin so klug als wie\n",
    "zuvor; Heisse Magister, heisse Doktor gar Und ziehe schon an die zehen Jahr Herauf, herab und\n",
    "quer und krumm Meine Schüler an der Nase herum Und sehe, dass wir nichts wissen können! Das\n",
    "will mir schier das Herz verbrennen. Zwar bin ich gescheiter als all die Laffen, Doktoren, Magister,\n",
    "Schreiber und Pfaffen; Mich plagen keine Skrupel noch Zweifel, F¨urchte mich weder vor Hölle noch\n",
    "Teufel Dafür ist mir auch alle Freud entrissen, Bilde mir nicht ein, was Rechts zu wissen, Bilde mir\n",
    "nicht ein, ich könnte was lehren, Die Menschen zu bessern und zu bekehren. Auch hab ich weder\n",
    "Gut noch Geld, Noch Ehr und Herrlichkeit der Welt; Es m¨ochte kein Hund so l¨anger leben! Drum\n",
    "hab ich mich der Magie ergeben, Ob mir durch Geistes Kraft und Mund Nicht manch Geheimnis\n",
    "w¨urde kund; Dass ich nicht mehr mit saurem Schweiss Zu sagen brauche, was ich nicht weiss; Dass\n",
    "ich erkenne, was die Welt Im Innersten zusammenh¨alt, Schau alle Wirkenskraft und Samen, Und\n",
    "tu nicht mehr in Worten kramen.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-406bc5dbee70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuffman_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#print('Encoded text:',encoded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-406bc5dbee70>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuffman_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#print('Encoded text:',encoded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'h'"
     ]
    }
   ],
   "source": [
    "# Test element:\n",
    "alphabet = get_alphabet(text2.lower())\n",
    "\n",
    "code, tree = Huffman_code(alphabet)\n",
    "\n",
    "encoded = ''.join([code[t] for t in text2.lower()])\n",
    "#print('Encoded text:',encoded)\n",
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 12,\n",
       " 'r': 69,\n",
       " 'u': 50,\n",
       " 'j': 2,\n",
       " 'v': 3,\n",
       " 'e': 131,\n",
       " 'd': 45,\n",
       " ';': 5,\n",
       " 'i': 77,\n",
       " 'o': 22,\n",
       " 'n': 83,\n",
       " '\\n': 12,\n",
       " 'c': 43,\n",
       " 'f': 13,\n",
       " 'g': 15,\n",
       " 'p': 5,\n",
       " '¨': 8,\n",
       " 'ö': 2,\n",
       " ' ': 185,\n",
       " 'a': 51,\n",
       " 'q': 1,\n",
       " 'w': 20,\n",
       " 'k': 17,\n",
       " ',': 23,\n",
       " 'ü': 1,\n",
       " 'b': 17,\n",
       " 's': 65,\n",
       " 't': 38,\n",
       " 'm': 35,\n",
       " 'h': 72,\n",
       " 'l': 32,\n",
       " '.': 4,\n",
       " '!': 4}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text: Hello Georgi and Maia, i don't know why but it works.\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "i = 0\n",
    "while i < len(encoded): # decoding using the binary graph\n",
    "    ch = encoded[i]  \n",
    "    act = tree[ch]\n",
    "    while not isinstance(act, str):\n",
    "        i += 1\n",
    "        ch = encoded[i]  \n",
    "        act = act[ch]        \n",
    "    decoded.append(act)          \n",
    "    i += 1\n",
    "\n",
    "print('Decoded text:',''.join(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "def draw_tree(tree, prefix = ''):    \n",
    "    if isinstance(tree, str):            \n",
    "        descr = 'N%s [label=\"%s:%s\", fontcolor=blue, fontsize=16, width=2, shape=box];\\n'%(prefix, tree, prefix)\n",
    "    else: # Node description\n",
    "        descr = 'N%s [label=\"%s\"];\\n'%(prefix, prefix)\n",
    "        for child in tree.keys():\n",
    "            descr += draw_tree(tree[child], prefix = prefix+child)\n",
    "            descr += 'N%s -> N%s;\\n'%(prefix,prefix+child)\n",
    "    return descr\n",
    "\n",
    "\n",
    "import subprocess\n",
    "with open('graph.dot','w') as f:\n",
    "    f.write('digraph G {\\n')\n",
    "    f.write(draw_tree(tree))\n",
    "    f.write('}') \n",
    "subprocess.call('dot -Tpng graph.dot -o graph.png', shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'c', '1': {'0': 'a', '1': 'b'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': '0', 'a': '10', 'b': '11'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
